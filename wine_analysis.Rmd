---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
winedata <- read.csv("~/Documents/senior_year/stat471/final_project/wine-reviews/winemag-data-130k-v2.csv")
```

```{r}
summary(winedata)
names(winedata)
```

remove duplicated rows:
```{r}
winedata_unique = unique(winedata[,-1])
```

Take out entries with missing values in important categories:
```{r}
winedata_clean <- winedata_unique[!is.na(winedata_unique$price),]
winedata_clean <- winedata_unique[winedata_unique$country!="",]
winedata_clean <- winedata_unique[winedata_unique$description!="",]
winedata_clean.reg <- winedata_unique[winedata_unique$region_1!="",]
```

Take a subset of data to make PCA tinkering more efficent:
```{r}
#Uncomment line below to take subset of data
#winedata_subset = sample_n(winedata,50000)
#Uncomment line below to use entire dataset instead of subset
winedata_subset = winedata_clean
dtm_ready_df = winedata_subset[ ,c(1, 2)]
```


Okay, let's create a corpus, clean it, and create a DTM!
```{r}
library(tm)
corp.original <- VCorpus(VectorSource(dtm_ready_df$description))
corp = tm_map(corp.original, removePunctuation) 
corp = tm_map(corp, removeNumbers) 
corp = tm_map(corp, content_transformer(tolower) ,lazy=TRUE) 
corp = tm_map(corp, content_transformer(removeWords), c("like") ,lazy=TRUE)
corp = tm_map(corp, content_transformer(removeWords), stopwords("english"))
corp = tm_map(corp, content_transformer(stemDocument) ,lazy=TRUE) 
corp = tm_map(corp, stripWhitespace)

# Convert to document term matrix
dtm <- DocumentTermMatrix(corp)
# Reduce matrix sparsity to better deal with LDA later on
dtms = removeSparseTerms(dtm, .995)
dtm_matrix = as.matrix(dtms)
```

Remove wines that have no description from DTM to avoid LDA errors
```{r}
rowTotals <- apply(dtm_matrix , 1, sum) #Find the sum of words in each Document
dtm_matrix   <- dtm_matrix[rowTotals> 0, ]           #remove all docs without words
```

Conduct LDA for given number of topics
```{r}
library(topicmodels)
number_of_topics = 20
ldaOut20_all <-LDA(dtm_matrix, number_of_topics, method="Gibbs")
terms(ldaOut,10)
```

The following chunk will generate the topic probilities for each document:
```{r}
dic = Terms(dtms)

# Specify this dictionary when creating the dtm for the new articles, which will limit the dtm it creates to only the words that also appeared in the archive. In the example below, 'ldaOut' would be the name assigned to the topic model we created in Step earlier.

new_dtm = DocumentTermMatrix(corp, control=list(dictionary = dic))
new_dtm = new_dtm[rowSums(as.matrix(new_dtm))!=0,]
topic_probabilities20 = posterior(ldaOut20_all, new_dtm)
```

Run this chunk to generate a dataframe that gives the highest ranked topic for each wine.
```{r}
articles_w_topics20 = as.data.frame(cbind(winedata[rowTotals> 0, ], max.col(topic_probabilities20$topics)))
# Rename a column in R
colnames(articles_w_topics20)[colnames(articles_w_topics20)=="max.col(topic_probabilities20$topics)"] <- "topic"
articles_w_topics20$topic = as.factor(articles_w_topics20$topic)
```

Run this chunk to generate a dataframe that gives the probabilities of each topic for each wine.
```{r}
articles_w_topics20 = as.data.frame(cbind(winedata_clean[rowTotals> 0, ], (topic_probabilities20$topics)))
# Rename a column in R
```

Rename columns from topic numbers to topic_n naming convention. Example: from `1` to `topic_1`.
```{r}
for (i in 1:20){
  colnames(articles_w_topics20)[colnames(articles_w_topics20)==i] <- paste("topic_", i, sep="")
}
```

Constructing a function to later use to extract year from a string
```{r}
# create a helper function
yearExtract <- function(string) {
  t <- regmatches(string, regexec("[0-9]{4}", string))
  sapply(t, function(x) {
    if(length(x) > 0){
      return(as.numeric(x))
    } else {
      return(NA)    
    }
  })
}
```

Use our new function to extract the vintage year from wine title. Note, around 5% of wines don't have a year in the title and the regex match can possibly catch a 4 digit number other than year if present.
```{r}
articles_w_topics20$vintage_year = (yearExtract(as.character(articles_w_topics20$title)))
```

Create a new variable that is a categorical grouping of the year.
```{r}
articles_w_topics20$vintage_year_cat = NA
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=2010&articles_w_topics20$vintage_year<=2017] <- "2010-2017"
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=2000&articles_w_topics20$vintage_year<=2009] <- "2000-2009"
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=1980&articles_w_topics20$vintage_year<=1999] <- "1980-1999"
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=1950&articles_w_topics20$vintage_year<=1979] <- "1950-1979"
```

Now let's create a train test split:
```{r}
set.seed(42) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 80% of data as sample from total 'n' rows of the data  
sample <- sample.int(n = nrow(winedata_clean), size = floor(.80*nrow(winedata_clean)), replace = F)
train <- winedata_clean[sample, ]
test  <- winedata_clean[-sample, ]
```

PCA - not effective because topics are calculated to assume minimum correlation
```{r}
topics <- prcomp(articles_w_topics20[,c(15:34)], scale=TRUE)
round(topics$rotation, 5)

cpve <- 100*cumsum((topics$sdev)^2)/20   

# Scree plot of CPVE's
plot(seq(1:20), cpve, pch=16, ylim=c(0, 100),
     main="Cumulative Proportion of Variance Explained",
     xlab="Number of PC's Used")
```

Generate a model:
```{r}
# summary(lm(points ~ log(price)+ taster_name + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20 + topic_21 + topic_22 + topic_23 + topic_24 + topic_25 + topic_26 + topic_27 + topic_28 + topic_29 + topic_30, articles_w_topics30))

summary(lm(points ~ log(price) + taster_name + vintage_year_cat + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20, articles_w_topics20))

# Run regsubsets for model selection
subsets = regsubsets(points ~ log(price) + taster_name + country + vintage_year_cat + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20, data=articles_w_topics20, nvmax=50,method="backward")

#sumarize and print results
subsets.fit = summary(subsets)
subsets.fit$which
data.frame(variables = (1:length(subsets.fit$rsq)),
           r_squared = subsets.fit$rsq,
           rss = subsets.fit$rss,
           bic = subsets.fit$bic,
           cp = subsets.fit$cp)
plot(subsets.fit$rsq, xlab="Number of predictors", ylab="R-square", col="red", type="p", pch=16)
plot(subsets.fit$rss, xlab="Number of predictors", ylab="RSS", col="blue", type="p", pch=16)

plot(subsets.fit$cp, xlab="Number of predictors", 
     ylab="cp", col="red", type="p", pch=16)
plot(subsets.fit$bic, xlab="Number of predictors", 
     ylab="bic", col="blue", type="p", pch=16)
plot(subsets.fit$adjr2, xlab="Number of predictors", 
     ylab="adjr2", col="green", type="p", pch=16)
```

final model
```{r}
final.lm <- lm(points ~ log(price) + taster_name + country + vintage_year_cat + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20, data=articles_w_topics20)

final.lm.1 <- lm(points ~ log(price) + taster_name + vintage_year_cat + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20, data=articles_w_topics20)

anova(final.lm.1,final.lm)
summary(final.lm)
```




