---
title: 'STAT 471 Final Project: Predicting Wine Points using Taste Description and
  Text Analysis'
author:
- Duncan McCrae
- George Poon
- Jon Edson
output:
  word_document: default
  html_notebook: default
---

```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      tidy = TRUE, fig.width = 7, fig.height = 4,
                      fig.align='left', dev = 'pdf')
if(!require("pacman")) install.packages("pacman")

pacman::p_load(dplyr, ggplot2, glmnet, ggrepel, tm, wordcloud, RTextTools,
               data.table,psych,topicmodels,randomForest)

setwd("C:/Users/george/Desktop/STAT 471/project")
wine.dat <- read.csv("winemag-data-130k-v2.csv", encoding="UTF-8",stringsAsFactors=FALSE)
```

##Executive Summary
###Background
The 100-point wine scoring system has become the de facto benchmark of quality in the wine industry. Since Robert Parker begain releasing these scores in the 70s, most other major wine publications (including Wine Spectator, Wine Enthusiast, and International Wine Cellar) have begun rating wines on this scale. The reason for its widespread adoption is clear: consumers need genuine signals of quality in order to make informed purchasing decisions. Such a signal is made even more valuable by the fact that wine quality is dependent on a high number of variables. It can be very difficult for consumers to differentiate between the myriad combination varieties, vineyards, and vintages. Consequently, expert wine scores have become popular tools in many areas of the industry. They are strategically used by online and brick and mortar wine stores to sell their stock, and by vineyards to help push their wines downstream.  

However many - including the administrators of these publications - have reservations about this rating system. Many wine-rating publications have conflicts of interest (because they receive advertising revenue and free samples from vineyards, or because they sell wine in addition to rating it) (https://www.nytimes.com/2006/08/13/business/yourmoney/13rate.html). Some argue that critics' scores are more a reflection of their preferences that the absolute quality of the wine, which might homogenize the industry as producers choose styles of wines that tend to score better (https://www.nytimes.com/2006/08/13/business/yourmoney/13rate.html). Finally there is an increasing body of literature that suggests that experts cannot reliably distinguish between high and low quality wine, and that their preferences do not line up with those of non-experts (http://ageconsearch.umn.edu/record/37328/files/AAWE_WP16.pdf, http://www.daysyn.com/Morrot.pdf, https://www.theguardian.com/science/2011/apr/14/expensive-wine-cheap-plonk-taste, https://www.theguardian.com/lifeandstyle/2013/jun/23/wine-tasting-junk-science-analysis, https://www.pnas.org/content/105/3/1050.full, https://ideas.repec.org/p/hhs/hastef/0700.html). 

##Goal of the Study
The goal of this study is the answer the question: What do these expert wine scores reflect, if not the underlying quality of the wine? As we discuss further in the conclusions, it would be interesting to explore the relationship between the objective characteristics of wine (i.e. chemical makeup) and expert scores, but this data is not availiable at this time. 

##Data
###Data Summary
To achieve these goals, we analyzed a set of 111,538 unique wines reviews by Wine Enthusiast (https://www.winemag.com/), one of the largest wine-rating publications in the world. For each of these observations, this dataset provided to the following variables:  

1. points: This is the score Wine Enthusiast rated the wine on a scale of 1-100. According to Wine Enthusiast:  
  
> Ratings reflect what our editors felt about a particular product. Beyond the rating, we encourage you to read the accompanying tasting note to learn about a product's special characteristics.  
> Classic 98-100: The pinnacle of quality.  
> Superb 94-97: A great achievement.  
> Excellent 90-93: Highly recommended.  
> Very Good 87-89: Often good value; well recommended.  
> Good 83-86: Suitable for everyday consumption; often good value.  
> Acceptable 80-82: Can be employed in casual, less-critical circumstances.  
> Products deemed Unacceptable (receiving a rating below 80 points) are not reviewed.  
  
2. price: The cost for a bottle of the wine in USD
3. country: The country that the wine is from
4. description: Tasting notes written by the reviewer
5. designation: The vineyard within the winery where the grapes that made the wine are from
6. province: The province or state that the wine is from
7. region_1: The wine growing area in a province or state (ie Napa)
8. region_2: Sometimes there are more specific regions specified within a wine growing area (ie Rutherford inside the Napa Valley), but this value can sometimes be blank
9. taster_name
10. taster_twitter_handle
11. title: The title of the wine review, which often contains the vintage if you're interested in extracting that feature
12. variety: The type of grapes used to make the wine (ie Pinot Noir)
13. winery: The winery that made the wine  

According to Wine Enthusiast:  

> All tastings reported in the Buying Guide are performed blind. Typically, products are tasted in peer-group flights of from 5-8 samples. Reviewers may know general information about a flight to provide context-vintage, variety or appellation-but never the producer or retail price of any given selection. When possible, products considered flawed or uncustomary are retasted. (https://253qv1sx4ey389p9wtpp9sj0-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/BG_Info_Panel.pdf)  
  
This should minimize many potential sources of bias. However, experts are - by definition - not unbiased estimators of quality. In other words, their scores likely do not reflect the true average score that consumers would give the wine, because their preferences likely differ from that of the average consumer. Based on the existing literature, we expect that this bias is small compared to the test-to-test variance (noise in experts' scores). We hope that the large number of observations in this dataset will produce precise results despite this potentially high variance. Other sources are bias which we know less about are selection bias and survivorship bias. Wine Enthusiast does not rate every wine, or perform statistically rigorous sampling. In fact most of the wines they rate are free samples samples submitted by vineyards. Additionally Wine Enthusiast does not public ratings for wines which scored below 80 points.  

Interestingly, these variables constitute most of the information that an individual might use to make a purchasing decision about a wine that they had never tried.  However we are missing a few variables that previous literature has found to predict quality: color, etc.

```{r, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE, 
                      tidy = TRUE, fig.width = 7, fig.height = 4,
                      fig.align='left', dev = 'pdf')
if(!require("pacman")) install.packages("pacman")

pacman::p_load(dplyr, ggplot2, glmnet, ggrepel, tm, wordcloud, RTextTools,
               data.table,psych,topicmodels,kableExtra)

working_directory  <- paste(getwd(), "/wine-reviews", sep="")
setwd(working_directory)
winedata <- read.csv("winemag-data-130k-v2.csv", encoding="UTF-8",stringsAsFactors=FALSE)
```


###Data Cleaning
```{r,echo=F}
#remove duplicated rows:
winedata2 <- winedata[,-c(1,9)]
a <- nrow(winedata2)
winedata_unique = unique(winedata2)
b <- nrow(winedata_unique)
num_dupl <- a - b
#Take out entries with missing values in important categories:
winedata_clean <- winedata_unique[!is.na(winedata_unique$price),]
c <- nrow(winedata_clean)
num_no_price <- b - c 
winedata_clean <- winedata_clean[winedata_clean$country!="",]
d <- nrow(winedata_clean)
num_no_country <- c - d
winedata_clean <- winedata_clean[winedata_clean$description!="",]
e <- nrow(winedata_clean)
num_no_desc <- d - e
winedata_clean.reg <- winedata_clean[winedata_clean$region_1!="",]
f <- nrow(winedata_clean.reg)
num_no_reg <- e - f
```

```{r,echo=F}
cleaning_df <- data.frame(list(ayy=c("Original Data", "Duplicates","Missing Price","Missing Country","Clean Data","Missing Region","Clean Data With Region"),
                               obs=c(nrow(winedata),num_dupl,num_no_price,num_no_country,nrow(winedata_clean),num_no_reg,nrow(winedata_clean.reg))))

cleaning_df <- plyr::rename(cleaning_df, c(ayy="", obs="Observations Count"))

kable(cleaning_df) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, position = "left")
```
The original data required some cleaning to prepare it for analysis. One variable was simply unique row identifiers and thus was dropped. The information from region_2 is largely captured in region_1 variable, so it was dropped removed as well because of the excess amount of NA and specificity. We also removed observations with NAs in price and country because those are likely to be important predictors of sentiment. We also created a separate dataset composed of the observations with NA's from region_1 removed since some countries are simply to small to have regional specificity so we don't want to pollute the data. All of these operations may have introduced bias, and using a more sophisticated technique for dealing with this missing values is be an imporant next step for this analysis. The original data included 129,971, and - after performing the above operations - we were left with a clean set of 111,538 observations (93,580 with region data). 

###Exploratory Data Analysis
```{r,echo=F}
ggplot(data=winedata_clean, aes(winedata_clean$price)) + 
  geom_histogram(bins = 40) + 
  labs(title="Histogram of Price") +
  labs(x="Price (USD)", y="Count")
```

```{r,echo=F}
ggplot(data=winedata_clean[winedata_clean$price < 200, ], aes(winedata_clean$price[winedata_clean$price < 200])) + 
  geom_histogram(bins = 20) + 
  labs(title="Truncated Histogram of Price") +
  labs(x="Price (USD)", y="Count")
```
```{r,echo=F}
ggplot(data=winedata_clean, aes(winedata_clean$points)) + 
  geom_histogram(bins = 20) + 
  labs(title="Histogram of Score") +
  labs(x="Score", y="Count")
```
Price and Score are arguably the two most important variables in this dataset. Together they represent to value (quality per dollar) of a wine. There are noticeable differences between the distribution of score and price. While scores are distributred relatively normally (with the exception of a peak at 89), prices are right-skewed with a very long tail (the most expensive wine in this dataset is $3300).  

Wine price and points are somewhat correlated, with about 0.417 correlation coefficient. Wine Enthusiast claims to taste without prior knowledge of a wine's price. Therefore this might be evidence that it costs more to produce more expensive wine, or that producers can charge higher prices for better quality wine.  


```{r,echo=F}
tasters_df <- winedata_clean %>% filter(taster_name!="") %>% group_by(taster_name) %>% summarise(num_wine_tasted=n()) %>% arrange(desc(num_wine_tasted))

tasters_df <- plyr::rename(tasters_df, c(taster_name="Taster Name", num_wine_tasted="Number of Wines Tasted"))

kable(tasters_df[1:10,], caption = "Top 10 Most Prolific Tasters") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, position = "left")
```
A total of 19 wine tasters contributed to this dataset. Most of them are rather prolific and cover thousands of wine. The most prolific is Roger Voss, the European editor of Wine Enthusiast, who covers Bordeaux, Burgundy, Champagne, the Loire and South-West France as well as Portugal.  

```{r,echo=F}
country_dat <- winedata_clean %>% group_by(country) %>% summarize(median_points=median(points),median_price=median(price),n_wines_produced=n()) %>%
  arrange(desc(n_wines_produced,median_points,median_price))

country_dat_round <- country_dat
country_dat_round$median_points <- round(country_dat_round$median_points, 1)
country_dat_round$median_price <- round(country_dat_round$median_price, 1)
country_dat_round <- plyr::rename(country_dat_round, c(country="Country", median_points="Median Score", median_price="Median Price (USD)", n_wines_produced="Wine Rating Count"))

kable(country_dat_round[1:10,], caption = "Top 10 Countries by Number of Wine Ratings") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```
```{r,include=F}
median(winedata_clean$price)
median(winedata_clean$points)
```
We use the median to summarize the score and price at the country level, because the prices are so skewed. The median price of all wines is $25, and the median score is 88 points. The US is very well represented in this dataset, with its wines composing almost half of all reviews (more than the next 6 most represented countried combined). While median score and price at the country level provide some information about the quality and expense of wine, we need to look at the distributions of these variables to see what is really happening. 


```{r,echo=F}
top10_count <- country_dat_round[1:10,]$Country
winedata_top10_count <- winedata_clean[winedata_clean$country %in% top10_count, ] # only include countries which are in top 10 for reviews

ggplot(winedata_top10_count, aes(winedata_top10_count$country, winedata_top10_count$price)) + geom_boxplot() + 
  coord_cartesian(ylim = c(0, 100)) + 
  labs(title="Distribution of Price by Country (10 Most Represented Countries)") +
  labs(x="Country", y="Price")
```

```{r,echo=F}
ggplot(winedata_top10_count, aes(winedata_top10_count$country, winedata_top10_count$points)) + geom_boxplot() + 
  labs(title="Distribution of Score by Country (10 Most Represented Countries)") +
  labs(x="Country", y="Score")
```
From these plots, we find that - even at the country level - there are significant differences in prices and scores. Wine grapes are difficult to grow, with certain varieties requiring very specific climates. Thus, we would expect there to be significant differences to the degree that different countries have different climates.  

```{r,echo=F}
variet_dat <- winedata_clean %>% group_by(variety) %>% summarize(median_points=median(points),median_price=median(price),n_wines_produced=n()) %>%
  arrange(desc(n_wines_produced,median_points,median_price))

variet_dat2 <- plyr::rename(variet_dat, c(variety="Variety", median_points="Median Score", median_price="Median Price (USD)", n_wines_produced="Wine Rating Count"))
variet_dat2 <- variet_dat2[1:10,]

kable(variet_dat2, caption = "Top 10 Varieties by Number of Wine Ratings") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

```{r, include=F}
nrow(variet_dat)
sum(variet_dat[1:10,]$n_wines_produced) / nrow(winedata_clean)
```
Though 692 unqiue varieties are represented in this dataset, the top 10 most represented varieties constitute 56% of the total reviews. Here we can also see that the median price varies quite a lot between varieties. It is possible that this is due to costs of productions differing, or due to certain varieties being more demanded.  

```{r,echo=F}
top10_variet <- variet_dat[1:10,]$variety
winedata_top10_variet <- winedata_clean[winedata_clean$variety %in% top10_variet, ] # only include varieties which are in top 10 for reviews

ggplot(winedata_top10_variet, aes(winedata_top10_variet$variety, winedata_top10_variet$price)) + geom_boxplot() +
  coord_cartesian(ylim = c(0, 100)) + 
  labs(title="Distribution of Score by Price (10 Most Represented Varieties)") +
  labs(x="Variety", y="Price")
```
Interestingly, both the median and interquartile range of price varies much more between varieties than score.

```{r,echo=F}
ggplot(winedata_top10_variet, aes(winedata_top10_variet$variety, winedata_top10_variet$points)) + geom_boxplot() + 
  labs(title="Distribution of Score by Variety (10 Most Represented Varieties)") +
  labs(x="Variety", y="Score")
```
Though the interquartile ranges are similar, the median scores are quite different for some of these wines. This could be a result of tasters' personal preferences, or there could be many other reasons why certain varieties would tend to be better quality. We just don't have enough information here to say. 

```{r,echo=F}
province_dat <- winedata_clean.reg %>% group_by(province) %>% summarize(mean_points=median(points),mean_price=median(price)) %>%
  arrange(desc(mean_points,mean_price)) %>% 
  mutate(country=winedata_clean.reg[match(province,winedata_clean.reg$province),1],
         prov_country=paste(province,",",country))

province_100_dat <- winedata_clean.reg %>% group_by(province) %>% summarize(mean_points=median(points),mean_price=median(price), n_wine=n()) %>%
  filter(n_wine>=100) %>%
  arrange(desc(mean_points,mean_price)) %>% 
  mutate(country=winedata_clean.reg[match(province,winedata_clean.reg$province),1],
         prov_country=paste(province,",",country))

ggplot(province_100_dat[1:10,],aes(mean_points,mean_price)) +
  geom_point() +
  geom_label_repel(aes(label=prov_country),
                   box.padding   = 0.35, 
                   point.padding = 0.5,
                   segment.color = 'grey50') +
  theme_classic() +
  labs(title="Top 10 Provinces by Median Score", 
       x="Median Score", y="Median Price")
```
Looking at provinces has the advantage that each categorical level will have similar geographical features and climate, and therefore wine quality (in theory). However, even provincial level aggregation may be too broad. None of the traditional wine provinces such as Burgundy, Bordeaux or Northern California made it into the top 10 average points province list. This may due to the large volume of wine produced in those regions driving down the wine's median quality. Meanwhile small regions like Madeira (a Portuguese Atlantic island) are likely to have limited wine outputs, and a higher chance of producing exclusively high-quality wines.  

```{r,echo=F}
region_dat <- winedata_clean.reg %>% group_by(region_1) %>% summarize(mean_points=median(points),mean_price=median(price)) %>%
  arrange(desc(mean_points,mean_price)) %>% 
  mutate(country=winedata_clean.reg[match(region_1,winedata_clean.reg$region_1),1],
         province=winedata_clean.reg[match(region_1,winedata_clean.reg$region_1),6],
         reg_prov=paste(region_1,",",province))

ggplot(region_dat[1:10,],aes(mean_points,mean_price)) +
  geom_point() +
  geom_label_repel(aes(label=reg_prov),
                   box.padding   = 0.35, 
                   point.padding = 0.5,
                   segment.color = 'grey50') +
  theme_classic() +
  labs(title="Top 10 Regions by Median Score", 
       x="Median Score", y="Median Price")
```
Although the majority of observations also contain a region value, the lack of it does not necessarily suggest that the observation is erronious since many wines are from small countries or too non-specific in its origin to warrant region specifications. On the flip side, having a regional label also does not gurantee its quality. The majority of wine-producing regions with high points are located in Burgundy, which has a rich history of wine production. Compared to Bordeaux and other regions that place emphasis on individual chateaus or wineries, Burgundy is famous for its regional consistency as all wines made from the same area - no matter the producer - are often labeled as the same variety. This speaks to Burgundian winemakers' confidence in the reputation of its terroir, or the set of all attributes of the phenotype of the land.  

```{r,echo=F}
winery_dat <- winedata_clean.reg %>% group_by(winery) %>% summarize(mean_points=median(points),mean_price=median(price)) %>%
  arrange(desc(mean_points,mean_price)) %>%
  mutate(country=winedata_clean.reg[match(winery,winedata_clean.reg$winery),1],
         province=winedata_clean.reg[match(winery,winedata_clean.reg$winery),6],
         winery_prov=paste(winery,",",province))

ggplot(winery_dat[1:10,],aes(mean_points,mean_price)) +
  geom_point() +
  geom_label_repel(aes(label=winery_prov),
                   box.padding   = 0.35, 
                   point.padding = 0.3,
                   segment.color = 'grey50') +
  theme_classic() +
  labs(title="Top 10 Wineries by Median Score", 
       x="Median Points", y="Median Price")
```
The highest rated (and often most costly) wineries tend to be located in either France or California. This is somewhat fitting, as French and Californian wines have been in competing fiercely since the 1976 Judgment of Paris.



```{r}
winedata_clean %>% filter(winery!="") %>% group_by(winery) %>% summarise(num_produced=n()) %>% arrange(desc(num_produced)) %>%
  mutate(province=winedata_clean[match(winery,winedata_clean$winery),6])
```

Thus far we have have explored straightforward features in the dataset. Description, is a particularly interesting feature, containing the reviewer's assessment of quality and a description of the wine's characteristics and taste profile. These descriptions can help may our understanding of wine more nuanced. However since descriptions are naturally unstructured text data we need to develop a tactic for handling them. We chose to use LDA topic modeling. This unsupervised learning method groups wine descriptions into topics by examining patterns of words that frequently co-occur in the same descriptions.

We explored building topic models with various numbers of topics. Ultimately, we settled on 20 topics, as those topic made the most intuitive sense, and any further increase in the number of topics resulted in a negligible improvement in training error.

Take a subset of data to make PCA tinkering more efficent:
```{r}
#Uncomment line below to take subset of data
#winedata_subset = sample_n(winedata,50000)
#Uncomment line below to use entire dataset instead of subset
winedata_subset = winedata_clean
dtm_ready_df = winedata_subset[ ,c(1, 2)]
```

```{r}
#Okay, let's create a corpus, clean it, and create a DTM!

# corp.original <- VCorpus(VectorSource(dtm_ready_df$description))
# corp = tm_map(corp.original, removePunctuation) 
# corp = tm_map(corp, removeNumbers) 
# corp = tm_map(corp, content_transformer(tolower) ,lazy=TRUE) 
# corp = tm_map(corp, content_transformer(removeWords), c("like") ,lazy=TRUE)
# corp = tm_map(corp, content_transformer(removeWords), stopwords("english"))
# corp = tm_map(corp, content_transformer(stemDocument) ,lazy=TRUE) 
# corp = tm_map(corp, stripWhitespace)
# 
# # Convert to document term matrix
# dtm <- DocumentTermMatrix(corp)
# # Reduce matrix sparsity to better deal with LDA later on
# dtms = removeSparseTerms(dtm, .995)
# dtm_matrix = as.matrix(dtms)
```

```{r}
#Remove wines that have no description from DTM to avoid LDA errors
# rowTotals <- apply(dtm_matrix , 1, sum) #Find the sum of words in each Document
# dtm_matrix   <- dtm_matrix[rowTotals> 0, ]           #remove all docs without words
```

We then used our LDA model to generate the individual probabilities of each topic for each description. This effectively gave us a probability loading on each of the 20 topics, for each wine. We explored using either all 20 probability loadings or classifying each wine to the highest ranked topic. We found that when predicting for points the 20 topics probabilities resulting in a significantly lower testing error than taking the highest rank topic. Intuitively this makes sense, since wines can have complex taste profiles and may often fall into multiple topics, instead of into one cleanly.

We came up with names for each of the topics. However, it should be noted that these names are our interpretations of the highest ranked culusters of words in each topic - not anything objectivley generated.  

topic 1: toasty, dry flavor 
topic 2: strong, tart flavor 
topic 3: soft, fruity flavor 
topic 4: balance, fruity flavor
topic 5: blend of grape variety
topic 6: deep, spicy flavors 
topic 7: complex flavor and after-taste
topic 8: creamy, rich flavor
topic 9: ripe, fruity flavor
topic 10: melon, full body flavor

topic 11: herbal, earthy flavor
topic 12: light, citrus flavor
topic 13: crisp, acidic flavor
topic 14: differnet blends of berries
topic 15: good balance of alcoholic and non-alcoholic qualities
topic 16: wine that has not aged completely
topic 17: flavors that enhance other wine characteristics
topic 18: chocolate, coffee like flavor
topic 19: terroir and the fermentation process
topic 20: wine that tells of the storage process

```{r}
#Conduct LDA for given number of topics

# number_of_topics = 20
# ldaOut20_all <-LDA(dtm_matrix, number_of_topics, method="Gibbs")
load("C:/Users/george/Desktop/STAT 471/project/lda_20_image4.RData")
terms(ldaOut20_all,10)
```

We also assigned the highest ranked topic for each wine, and for each of the top three wine producing countries - USA, France and Italy as well as for each of the province that produced over 1000 wines for each country. At a glance our topic modeling matches the expert concensus for each geogrpahical region. American wines, especially those from California, are known for  the creative blends of different grapes variety to achieve the best taste (topic 5). Frenech wines are known for their soft fruity flavors which reflect the terroir of the regions. On the other hand, Italian wines are often more spicy and tannic, making them deesirable for accompanying desserts. 

```{r}
#The following chunk will generate the topic probilities for each document:
# dic = Terms(dtms)
# 
# # Specify this dictionary when creating the dtm for the new articles, which will limit the dtm it creates to only the words that also appeared in the archive. In the example below, 'ldaOut' would be the name assigned to the topic model we created in Step earlier.
# 
# new_dtm = DocumentTermMatrix(corp, control=list(dictionary = dic))
# new_dtm = new_dtm[rowSums(as.matrix(new_dtm))!=0,]
# topic_probabilities20 = posterior(ldaOut20_all, new_dtm)
```

```{r}
#Run this chunk to generate a dataframe that gives the highest ranked topic for each wine.

# articles_w_topics20 = as.data.frame(cbind(winedata_clean[rowTotals> 0, ], max.col(topic_probabilities20$topics)))

# # Rename a column in R

# colnames(articles_w_topics20)[colnames(articles_w_topics20)=="max.col(topic_probabilities20$topics)"] <- "topic"
# articles_w_topics20$topic = as.factor(articles_w_topics20$topic)
```

```{r}
#Run this chunk to generate a dataframe that gives the probabilities of each topic for each wine.

# articles_w_topics20 = as.data.frame(cbind(winedata_clean[rowTotals> 0, ], (topic_probabilities20$topics)))
```

```{r}
#Rename columns from topic numbers to topic_n naming convention. Example: from `1` to `topic_1`.

# for (i in 1:20){
#   colnames(articles_w_topics20)[colnames(articles_w_topics20)==i] <- paste("topic_", i, sep="")
# }
```

```{r}
articles_w_topics20$country_trimmed = "Other"
articles_w_topics20$country_trimmed[articles_w_topics20$country=="Italy"] <- "Italy"
articles_w_topics20$country_trimmed[articles_w_topics20$country=="France"] <- "France"
articles_w_topics20$country_trimmed[articles_w_topics20$country=="US"] <- "US"
articles_w_topics20$country_trimmed <- as.factor(articles_w_topics20$country_trimmed)
```

```{r}
country_topic <- articles_w_topics20 %>% filter(!(country_trimmed %in% "Other")) %>% group_by(country_trimmed) %>% summarise(m_topic_1 = mean(topic_1), m_topic_2 = mean(topic_2), m_topic_3 = mean(topic_3), m_topic_4 = mean(topic_4), m_topic_5 = mean(topic_5), m_topic_6 = mean(topic_6), m_topic_7 = mean(topic_7), m_topic_8 = mean(topic_8), m_topic_9 = mean(topic_9), m_topic_10 = mean(topic_10), m_topic_11 = mean(topic_11), m_topic_12 = mean(topic_12), m_topic_13 = mean(topic_13), m_topic_14 = mean(topic_14), m_topic_15 = mean(topic_15), m_topic_16 = mean(topic_16), m_topic_17 = mean(topic_17), m_topic_18 = mean(topic_18), m_topic_19 = mean(topic_19), m_topic_20 = mean(topic_20))

cbind(country_topic,max_prob_topic=
colnames(country_topic[-1])[max.col(country_topic[-1],ties.method="first")])
```

```{r}
province_topic <- articles_w_topics20 %>% filter(!(country_trimmed %in% "Other")) %>% group_by(province) %>% summarise(m_topic_1 = mean(topic_1), m_topic_2 = mean(topic_2), m_topic_3 = mean(topic_3), m_topic_4 = mean(topic_4), m_topic_5 = mean(topic_5), m_topic_6 = mean(topic_6), m_topic_7 = mean(topic_7), m_topic_8 = mean(topic_8), m_topic_9 = mean(topic_9), m_topic_10 = mean(topic_10), m_topic_11 = mean(topic_11), m_topic_12 = mean(topic_12), m_topic_13 = mean(topic_13), m_topic_14 = mean(topic_14), m_topic_15 = mean(topic_15), m_topic_16 = mean(topic_16), m_topic_17 = mean(topic_17), m_topic_18 = mean(topic_18), m_topic_19 = mean(topic_19), m_topic_20 = mean(topic_20), n_wine = n()) %>% filter(n_wine>1000)

cbind(province_topic,max_prob_topic=
colnames(province_topic[c(-1,-22)])[max.col(province_topic[c(-1,-22)],ties.method="first")])
```

We suspected that the vintage of each wine (year it was produced) may influence quality. So we extracted the year variable from the title of the review. However, since we don't know the date of each wine review we are unable to calculate the age of the wine at time of review. To accomidate for this we bucketed wines into 4 vintage groups 2010-2017, 2000-2009, 1980-1999, and 1950-1979. 

```{r}
#Constructing a function to later use to extract year from a string
yearExtract <- function(string) {
  t <- regmatches(string, regexec("[0-9]{4}", string))
  sapply(t, function(x) {
    if(length(x) > 0){
      return(as.numeric(x))
    } else {
      return(NA)    
    }
  })
}
```

```{r}
#Use our new function to extract the vintage year from wine `title`. Note, around 5% of wines don't have a year in the title and the regex match can possibly catch a 4 digit number other than year if present.
articles_w_topics20$vintage_year = (yearExtract(as.character(articles_w_topics20$title)))
articles_w_topics20 <- articles_w_topics20[!is.na(articles_w_topics20$vintage_year),]
```

```{r}
#Create a new variable that is a categorical grouping of the year.
articles_w_topics20$vintage_year_cat = NA
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=2010&articles_w_topics20$vintage_year<=2017] <- "2010-2017"
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=2000&articles_w_topics20$vintage_year<=2009] <- "2000-2009"
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=1980&articles_w_topics20$vintage_year<=1999] <- "1980-1999"
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=1950&articles_w_topics20$vintage_year<=1979] <- "1950-1979"
```

```{r}
articles_w_topics20$log_price <- log(articles_w_topics20$price)
```

##Regression
Now we are ready to to perform regression analysis, however, we will first create a 80:20 training/testing split to validate our model. 
```{r}
#Now let's create a train test split
set.seed(42) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 80% of data as sample from total 'n' rows of the data  
sample <- sample.int(n = nrow(articles_w_topics20), size = floor(.80*nrow(articles_w_topics20)), replace = F)
train <- articles_w_topics20[sample, ]
test  <- articles_w_topics20[-sample, ]
```

We attempted to use principal component analysis to attempt to reduce the number of topics in order to increase interpretability of our model. However, since the topic models are generated in a way that each topic is maximally independent of each other, this approach is not effective as each principal component explains a small amount of variance in the data. The cumulative variance plot below shows this.

```{r}
#PCA - not effective because topics are calculated to assume minimum correlation
topics <- prcomp(articles_w_topics20[,c(14:33)], scale=TRUE)
round(topics$rotation, 5)

cpve <- 100*cumsum((topics$sdev)^2)/20   

# Scree plot of CPVE's
plot(seq(1:20), cpve, pch=16, ylim=c(0, 100),
     main="Cumulative Proportion of Variance Explained",
     xlab="Number of PC's Used")
```

Much of the motivation for this project came from a desire to better understand what leads to a good wine. Building a model to predict a reviewer's point rating allows us to see what factors contribute to a high scoring wine. Between the original dataset and the addition features we created there are 45 possible predictors for our model (meaning 2^45 possible models). To assess which predictors should be included we conducted backward selection on OLS regression to find the best model at every possible number of predictors (1-45). 

As shown in charts below we used CP and BIC statistics to assess estimates of the testing error at each level. While we did find estimated testing error decreased with every variable added to the model (full 45 predictor model had lowest CP & BIC), the rate of improvement reduced significantly at 15-18 predictors. This can be seen by applying the elbow rule to the CP and BIC plots below.

```{r}
#Generate a model:

# summary(lm(points ~ log(price)+ taster_name + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20 + topic_21 + topic_22 + topic_23 + topic_24 + topic_25 + topic_26 + topic_27 + topic_28 + topic_29 + topic_30, articles_w_topics30))

summary(lm(points ~ log(price) + taster_name + vintage_year_cat + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20, train))

# Run regsubsets for model selection
subsets = regsubsets(points ~ log(price) + taster_name + country_trimmed + vintage_year_cat + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20, data=train, nvmax=50,method="backward")

#sumarize and print results
subsets.fit = summary(subsets)
subsets.fit$which
data.frame(variables = (1:length(subsets.fit$rsq)),
           r_squared = subsets.fit$rsq,
           rss = subsets.fit$rss,
           bic = subsets.fit$bic,
           cp = subsets.fit$cp)
coef(subsets,20)

plot(subsets.fit$rsq, xlab="Number of predictors", ylab="R-square", col="red", type="p", pch=16)
plot(subsets.fit$rss, xlab="Number of predictors", ylab="RSS", col="blue", type="p", pch=16)

plot(subsets.fit$cp, xlab="Number of predictors", 
     ylab="cp", col="red", type="p", pch=16)
plot(subsets.fit$bic, xlab="Number of predictors", 
     ylab="bic", col="blue", type="p", pch=16)
plot(subsets.fit$adjr2, xlab="Number of predictors", 
     ylab="adjr2", col="green", type="p", pch=16)
```

We also attempted to use random forest on our model to see if it would improve the performance. However, due to the large size of our model, random forest gave extremely unstable results that were slow to execute. Thus, we will keep using the linear model derived from best subsets selection. The formula is the following: 
points ~ log(price) + taster_name + country_trimmed + topic_1 + topic_2 + topic_3 + topic_5 + topic_7 +  topic_8 + topic_10 + topic_11 + topic_14 + topic_15 + topic_17. 

We obtained an adjusted R Squared of 0.515 from the training model. By validating this model with the testing data we obtained a test mean squared error of 4.57 and a residual standard error of 2.16, which means our model is significantly more accurate compared to a random guess in the range of scores. 
```{r}
#Random Forest
#rf.fit <- randomForest(points ~ log_price + taster_name  + country_trimmed + topic_1 + topic_2 + topic_3 + topic_5 + topic_7 +  topic_8 + topic_10 + topic_11 + topic_14 + topic_15 + topic_17, data=train, mtry=5, ntree=100)
#summary(rf.fit)
```

```{r}
#final model
final.lm <- lm(points ~ log(price) + taster_name + country_trimmed + topic_1 + topic_2 + topic_3 + topic_5 + topic_7 +  topic_8 + topic_10 + topic_11 + topic_14 + topic_15 + topic_17, data=train)

summary(final.lm)

test_MSE <- mean(((test$points - predict.lm(final.lm, test))^2),na.rm = TRUE)
test_MSE
```

Our final model shows us that while there are many attributes to a wine, a few explain most of the variation in point ratings quite well. Our model shows price to be a very strong predictor of points. This has interesting implications since there has been a good deal of controversy around the true impact of price. While it is predictive of points the direction of the effect is unclear. Since these are not blind reviews it is possible higher prices could influence reviewers to give better ratings.

Countries do also have a significant impact on price. The countries that had the most signifiant contributions to the model were France, Italy, and US. With France leading to highest ratings, then Italy, then US - when controlling for all other predictors in the model.

Perhaps most interesting was the findings from our topic modeling. It seems that wines that are described just one or two topics perform poorly, while wines that have attributes of many topics do best. The only topic that improved a wine's predicted points as it rose was Topic 7 "complex flavor and after taste". Both these findings show us that a complex and nuanced taste profile is ideal, while no specific elements of a taste profile are necessarily better than others. However, the data did reflect that wine's described as "ripe" would typically have lower ratings.