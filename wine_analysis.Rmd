---
title: "Wine Analysis"
author:
- Duncan McCrae
- George Poon
- Jon Edson
output: html_notebook
---

##Executive Summary
###Background
The 100-point wine scoring system has become the de facto benchmark of quality in the wine industry. Since Robert Parker begain releasing these scores in the 70s, the major wine publications in the world (including Wine Spectator, Wine Enthusiast, and International Wine Cellar) have all begun rating wines on this scale. However the even the administrators of these very publications have major reservations about this rating system. Additionally many wine publications have conflicts of interest (because they receive advertising revenue and free samples from vineyards, or because they sell wine in addition to rating it) (https://www.nytimes.com/2006/08/13/business/yourmoney/13rate.html). Some argue that critics' scores are more a reflection of their preferences that the absolute quality of the wine, which might homogenize the industry as producers choose styles of wines that tend to score better (https://www.nytimes.com/2006/08/13/business/yourmoney/13rate.html). Finally there are the much larger questions of whether experts can reliably distinguish between good and bad wine, and whether their preferences line up with those of non-experts. Numerous studies have attempted to answer these questions and have cast doubt on expert wine scores altogether (http://ageconsearch.umn.edu/record/37328/files/AAWE_WP16.pdf, http://www.daysyn.com/Morrot.pdf, https://www.theguardian.com/science/2011/apr/14/expensive-wine-cheap-plonk-taste, https://www.theguardian.com/lifeandstyle/2013/jun/23/wine-tasting-junk-science-analysis, https://www.pnas.org/content/105/3/1050.full, https://ideas.repec.org/p/hhs/hastef/0700.html). 

##Goal of the Study
The goal of this study is the answer the question: What do these expert wine scores reflect, if not the underlying quality of the wine? As we explain in the conclusions, it would be interesting to explore the relationship between the objective characteristics of wine (i.e. chemical makeup) and expert scores, but this data is not availiable at this time. 

```{r, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE, 
                      tidy = TRUE, fig.width = 7, fig.height = 4,
                      fig.align='left', dev = 'pdf')
if(!require("pacman")) install.packages("pacman")

pacman::p_load(dplyr, ggplot2, glmnet, ggrepel, tm, wordcloud, RTextTools,
               data.table,psych,topicmodels)

working_directory  <- paste(getwd(), "/wine-reviews", sep="")
setwd(working_directory)
wine.dat <- read.csv("winemag-data-130k-v2.csv", encoding="UTF-8",stringsAsFactors=FALSE)
```

```{r}
library(tidyr)
winedata <- read.csv("~/Documents/senior_year/stat471/final_project/wine-reviews/winemag-data-130k-v2.csv")
```

##Data
Wine is stable of modern fine dining culture and often the ones that reflect their origin or terroir garner the most praise from critics. It would be rather useful to be able to predict the variety, winery and location of wine based on description from the ciritics. This dataset is sraped from WineEnthusiast.com during the week of June 15th, 2017. Only wines with scores over 80 are kept in the dataset with nearly 13000 initial observations. 

To achieve these goals, we analyzed a set of 100k (CHECK THIS) unique wines from Wine Enthusiast (https://www.winemag.com/), one of the largest wine-rating publications in the world. For each of these observations, we had access to the following variables:  

1. points: This is the score Wine Enthusiast rated the wine on a scale of 1-100. According to Wine Enthusiast:  
  
> Ratings reflect what our editors felt about a particular product. Beyond the rating, we encourage you to read the accompanying tasting note to learn about a product's special characteristics.  
> Classic 98-100: The pinnacle of quality.  
> Superb 94-97: A great achievement.  
> Excellent 90-93: Highly recommended.  
> Very Good 87-89: Often good value; well recommended.  
> Good 83-86: Suitable for everyday consumption; often good value.  
> Acceptable 80-82: Can be employed in casual, less-critical circumstances.  
> Products deemed Unacceptable (receiving a rating below 80 points) are not reviewed.  
  
2. price: The cost for a bottle of the wine in USD
3. country: The country that the wine is from
4. description: Tasting notes written by the reviewer
5. designation: The vineyard within the winery where the grapes that made the wine are from
6. province: The province or state that the wine is from
7. region_1: The wine growing area in a province or state (ie Napa)
8. region_2: Sometimes there are more specific regions specified within a wine growing area (ie Rutherford inside the Napa Valley), but this value can sometimes be blank
9. taster_name
10. taster_twitter_handle
11. title: The title of the wine review, which often contains the vintage if you're interested in extracting that feature
12. variety: The type of grapes used to make the wine (ie Pinot Noir)
13. winery: The winery that made the wine  

Luckily, we expect these variables to be almost entirely free of bias, with the important exception of points. According to Wine Enthusiast:
> All tastings reported in the Buying Guide are performed blind. Typically, products are tasted in peer-group flights of from 5-8 samples. Reviewers may know general information about a flight to provide context-vintage, variety or appellation-but never the producer or retail price of any given selection. When possible, products considered flawed or uncustomary are retasted. (https://253qv1sx4ey389p9wtpp9sj0-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/BG_Info_Panel.pdf) 

These variables constitute almost all of the information that an individual might use to make a purchasing decision about a wine that they had never tried.  However we are missing a few variables that might predict how 


```{r}
summary(winedata)
names(winedata)
```


```{r}
#remove duplicated rows:
winedata <- winedata[,-c(1,9)]
winedata_unique = unique(winedata[,-1])
```


```{r}
#Take out entries with missing values in important categories:
winedata_clean <- winedata_unique[!is.na(winedata_unique$price),]
winedata_clean <- winedata_clean[winedata_unique$country!="",]
winedata_clean <- winedata_clean[winedata_unique$description!="",]
winedata_clean.reg <- winedata_clean[winedata_unique$region_1!="",]
```


##Data Cleaning/Summary
```{r,echo=F}
#price and Not very correlated
cor(winedata_clean$points,winedata_clean$price)
multi.hist(winedata_clean[,sapply(winedata_clean, is.numeric)])
```

First we removed the numerative column for repetitiveness, then region_2 was removed as well because of the excess amount of NA and specificity. We also removed observations with NAs in price and country because those are likely to be important predictors of sentiment. We then created a separate dataset with NAs from region_1 removed since some countries are simply to small to have regional specificity so we don't want to pollute the data. 

Wine price and points are somewhat correlated, with about 0.416 correlation coefficient. This makes sense because tasters generally try to avoid a priori knowledge about wine characteristics before tasting in order to be objective. However, the amount of effort that went into more expensively priced wine would reflect somewhat in the quality. 

Looking at the histograms of points and prices we can observe their distributional differences. While points are distributred relatively normally, prices are right-skewed with a few extremely expensive wines. 

```{r,echo=F}
winedata_clean %>% filter(taster_name!="") %>% group_by(taster_name) %>% summarise(num_wine_tasted=n()) %>% arrange(desc(num_wine_tasted))
```

There are a total of 19 wine tasters that contribute to this datasets. Most of them are rather prolific and cover thousands of wine. The most prolific of which is Roger Voss who is an editor for WineEnthusiast and covers most of France. 

```{r,echo=F}
winedata_clean %>% group_by(country) %>% summarize(mean_points=mean(points),mean_price=mean(price),n_wines_produced=n()) %>%
  arrange(desc(n_wines_produced,mean_points,mean_price))
```

```{r}
winedata_clean %>% group_by(province) %>% summarize(mean_points=mean(points),mean_price=mean(price),n_wines_produced=n()) %>%
  arrange(desc(n_wines_produced,mean_points,mean_price)) %>%
    mutate(country=winedata_clean[match(province,winedata_clean$province),1]) %>% filter(country %in% c("US","France","Italy","Spain","Portugal"),
                                                                                         n_wines_produced > 1000)
```

While mean points and mean price on a country level can tell us in some ways the general wine quality in a given country. These qualities should be taken with reservations since the countries like US and France dominate the market in terms of number of wines produced which would dilute the mean. This also implies that country would not be a good variable to predict because of the variation of wine quality across the aforementioned powerhouses of wine production. 

```{r}
winedata_clean %>% group_by(variety) %>% summarize(mean_points=mean(points),mean_price=mean(price),n_wines_produced=n()) %>%
  arrange(desc(n_wines_produced,mean_points,mean_price))
```


```{r,echo=F}
province_dat <- winedata_clean %>% group_by(province) %>% summarize(mean_points=mean(points),mean_price=mean(price)) %>%
  arrange(desc(mean_points,mean_price)) %>% 
  mutate(country=winedata_clean[match(province,winedata_clean$province),1],
         prov_country=paste(province,",",country))

province_100_dat <- winedata_clean %>% group_by(province) %>% summarize(mean_points=mean(points),mean_price=mean(price), n_wine=n()) %>%
  filter(n_wine>=100) %>%
  arrange(desc(mean_points,mean_price)) %>% 
  mutate(country=winedata_clean[match(province,winedata_clean$province),1],
         prov_country=paste(province,",",country))

ggplot(province_100_dat[1:10,],aes(mean_points,mean_price)) +
  geom_point() +
  geom_label_repel(aes(label=prov_country),
                   box.padding   = 0.35, 
                   point.padding = 0.5,
                   segment.color = 'grey50') +
  theme_classic() +
  labs(title="Top 10 Provinces With the Highest Scores", 
       x="Mean Points", y="Mean Price")
```

Looking at provinces is a much better idea as each one in general has much similar geographical features and climate, allowing for more consistent wine quality within each categorical level. However, even provincial level aggregation may be too broad. None of the traditional wine provinces such as Burgundy, Bordeaux or Northern California made it into the top 10 average points province list. This is likely due to the large volume of wine produced in those regions which has an effect on the wine's average quality. Meanwhile small regions like Madeira (a Portuguese Atlantic island) are likely to have limited wine outputs. 

```{r,echo=F}
region_dat <- winedata_clean.reg %>% group_by(region_1) %>% summarize(mean_points=mean(points),mean_price=mean(price)) %>%
  arrange(desc(mean_points,mean_price)) %>% 
  mutate(country=winedata_clean.reg[match(region_1,winedata_clean.reg$region_1),1],
         province=winedata_clean.reg[match(region_1,winedata_clean.reg$region_1),6],
         reg_prov=paste(region_1,",",province))

ggplot(region_dat[1:10,],aes(mean_points,mean_price)) +
  geom_point() +
  geom_label_repel(aes(label=reg_prov),
                   box.padding   = 0.35, 
                   point.padding = 0.5,
                   segment.color = 'grey50') +
  theme_classic() +
  labs(title="Top 10 Regions With the Highest Scores", 
       x="Mean Points", y="Mean Price")
```


Although the majority of observations also contain a region value, the lack of it does not necessarily guarantee that the observation is faulty since many wines are from small countries or too non-specific in its origin to warrant region specifications. On the flip side, having a regional label also does not gurantee its quality. Majority of wine-producing regions with high points are located in Burgundy. This has historical reasons. Compared to Bordeaux and other regions that place emphasis on individual chateaus or wineries, Burgundy is famous for its regional consistency as all wines made from the same area, no matter the prodoucer, is often labeled as the same variety. This speaks to Burgundian winemakers' confidence in the reputation of its terroir, or the set of all attributes of the phenotype of the land. 

```{r,echo=F}
winery_dat <- winedata_clean %>% group_by(winery) %>% summarize(mean_points=mean(points),mean_price=mean(price)) %>%
  arrange(desc(mean_points,mean_price)) %>%
  mutate(country=winedata_clean[match(winery,winedata_clean$winery),1],
         province=winedata_clean[match(winery,winedata_clean$winery),6],
         winery_prov=paste(winery,",",province))

ggplot(winery_dat[1:10,],aes(mean_points,mean_price)) +
  geom_point() +
  geom_label_repel(aes(label=winery_prov),
                   box.padding   = 0.35, 
                   point.padding = 0.3,
                   segment.color = 'grey50') +
  theme_classic() +
  labs(title="Top 10 Wineries With the Highest Scores", 
       x="Mean Points", y="Mean Price")
```

Generally European wineries charge a higher price than their Californian counterparts despite similairty in points. This reflects the higher esteem held by French wine despite the blind tasting catastrophe that it suffered during the 1976 Judgment of Paris. 

```{r}
winedata_clean %>% filter(winery!="") %>% group_by(winery) %>% summarise(num_produced=n()) %>% arrange(desc(num_produced)) %>%
  mutate(province=winedata_clean[match(winery,winedata_clean$winery),6])
```

Thus far we have have explored straightforward features in the dataset. Description, is a particularly interesting feature, containing the reviewer's assessment of quality and a description of the wine's characteristics and taste profile. These descriptions can help may our understanding of wine more nuanced. However since descriptions are naturally unstructured text data we need to develop a tactic for handling them. We chose to use LDA topic modeling. This unsupervised learning method groups wine descriptions into topics by examining patterns of words that frequently co-occur in the same descriptions.

We explored building topic models with various numbers of topics. Ultimately, we settled on 20 topics, as those topic made the most intuitive sense, and any further increase in the number of topics resulted in a negligible improvement in training error.

Take a subset of data to make PCA tinkering more efficent:
```{r}
#Uncomment line below to take subset of data
#winedata_subset = sample_n(winedata,50000)
#Uncomment line below to use entire dataset instead of subset
winedata_subset = winedata_clean
dtm_ready_df = winedata_subset[ ,c(1, 2)]
```

```{r}
#Okay, let's create a corpus, clean it, and create a DTM!
library(tm)
corp.original <- VCorpus(VectorSource(dtm_ready_df$description))
corp = tm_map(corp.original, removePunctuation) 
corp = tm_map(corp, removeNumbers) 
corp = tm_map(corp, content_transformer(tolower) ,lazy=TRUE) 
corp = tm_map(corp, content_transformer(removeWords), c("like") ,lazy=TRUE)
corp = tm_map(corp, content_transformer(removeWords), stopwords("english"))
corp = tm_map(corp, content_transformer(stemDocument) ,lazy=TRUE) 
corp = tm_map(corp, stripWhitespace)

# Convert to document term matrix
dtm <- DocumentTermMatrix(corp)
# Reduce matrix sparsity to better deal with LDA later on
dtms = removeSparseTerms(dtm, .995)
dtm_matrix = as.matrix(dtms)
```

```{r}
#Remove wines that have no description from DTM to avoid LDA errors
rowTotals <- apply(dtm_matrix , 1, sum) #Find the sum of words in each Document
dtm_matrix   <- dtm_matrix[rowTotals> 0, ]           #remove all docs without words
```

We then used our LDA model to generate the individual probabilities of each topic for each description. This effectively gave us a probability loading on each of the 20 topics, for each wine. We explored using either all 20 probability loadings or classifying each wine to the highest ranked topic. We found that when predicting for points the 20 topics probabilities resulting in a significantly lower testing error than taking the highest rank topic. Intuitively this makes sense, since wines can have complex taste profiles and may often fall into multiple topics, instead of into one cleanly.

We came up with names for each of the topics. However, it should be noted that these names are our interpretations of the highest ranked culusters of words in each topic - not anything objectivley generated.  

topic 1: toasty, dry flavor 
topic 2: strong, tart flavor 
topic 3: soft, fruity flavor 
topic 4: balance, fruity flavor
topic 5: blend of grape variety
topic 6: deep, spicy flavors 
topic 7: complex flavor and after-taste
topic 8: creamy, rich flavor
topic 9: ripe, fruity flavor
topic 10: melon, full body flavor

topic 11: herbal, earthy flavor
topic 12: light, citrus flavor
topic 13: crisp, acidic flavor
topic 14: differnet blends of berries
topic 15: good balance of alcoholic and non-alcoholic qualities
topic 16: wine that has not aged completely
topic 17: flavors that enhance other wine characteristics
topic 18: chocolate, coffee like flavor
topic 19: terroir and the fermentation process
topic 20: wine that tells of the storage process

```{r}
#Conduct LDA for given number of topics
library(topicmodels)
number_of_topics = 20
ldaOut20_all <-LDA(dtm_matrix, number_of_topics, method="Gibbs")
terms(ldaOut20_all,10)
```

We also assigned the highest ranked topic for each wine, and for each of the top three wine producing countries - USA, France and Italy as well as for each of the province that produced over 1000 wines for each country. At a glance our topic modeling matches the expert concensus for each geogrpahical region. American wines, especially those from California, are known for  the creative blends of different grapes variety to achieve the best taste (topic 5). Frenech wines are known for their soft fruity flavors which reflect the terroir of the regions. On the other hand, Italian wines are often more spicy and tannic, making them deesirable for accompanying desserts. 

```{r}
#The following chunk will generate the topic probilities for each document:
dic = Terms(dtms)

# Specify this dictionary when creating the dtm for the new articles, which will limit the dtm it creates to only the words that also appeared in the archive. In the example below, 'ldaOut' would be the name assigned to the topic model we created in Step earlier.

new_dtm = DocumentTermMatrix(corp, control=list(dictionary = dic))
new_dtm = new_dtm[rowSums(as.matrix(new_dtm))!=0,]
topic_probabilities20 = posterior(ldaOut20_all, new_dtm)
```

```{r}
#Run this chunk to generate a dataframe that gives the highest ranked topic for each wine.
articles_w_topics20 = as.data.frame(cbind(winedata_clean[rowTotals> 0, ], max.col(topic_probabilities20$topics)))
# Rename a column in R
colnames(articles_w_topics20)[colnames(articles_w_topics20)=="max.col(topic_probabilities20$topics)"] <- "topic"
articles_w_topics20$topic = as.factor(articles_w_topics20$topic)
```

```{r}
#Run this chunk to generate a dataframe that gives the probabilities of each topic for each wine.
articles_w_topics20 = as.data.frame(cbind(winedata_clean[rowTotals> 0, ], (topic_probabilities20$topics)))
# Rename a column in R
```

```{r}
#Rename columns from topic numbers to topic_n naming convention. Example: from `1` to `topic_1`.
for (i in 1:20){
  colnames(articles_w_topics20)[colnames(articles_w_topics20)==i] <- paste("topic_", i, sep="")
}
```

```{r}
articles_w_topics20$country_trimmed = "Other"
articles_w_topics20$country_trimmed[articles_w_topics20$country=="Italy"] <- "Italy"
articles_w_topics20$country_trimmed[articles_w_topics20$country=="France"] <- "France"
articles_w_topics20$country_trimmed[articles_w_topics20$country=="US"] <- "US"
articles_w_topics20$country_trimmed <- as.factor(articles_w_topics20$country_trimmed)
```

```{r}
country_topic <- articles_w_topics20 %>% filter(!(country_trimmed %in% "Other")) %>% group_by(country_trimmed) %>% summarise(m_topic_1 = mean(topic_1), m_topic_2 = mean(topic_2), m_topic_3 = mean(topic_3), m_topic_4 = mean(topic_4), m_topic_5 = mean(topic_5), m_topic_6 = mean(topic_6), m_topic_7 = mean(topic_7), m_topic_8 = mean(topic_8), m_topic_9 = mean(topic_9), m_topic_10 = mean(topic_10), m_topic_11 = mean(topic_11), m_topic_12 = mean(topic_12), m_topic_13 = mean(topic_13), m_topic_14 = mean(topic_14), m_topic_15 = mean(topic_15), m_topic_16 = mean(topic_16), m_topic_17 = mean(topic_17), m_topic_18 = mean(topic_18), m_topic_19 = mean(topic_19), m_topic_20 = mean(topic_20))

cbind(country_topic,max_prob_topic=
colnames(country_topic[-1])[max.col(country_topic[-1],ties.method="first")])
```

```{r}
province_topic <- articles_w_topics20 %>% filter(!(country_trimmed %in% "Other")) %>% group_by(province) %>% summarise(m_topic_1 = mean(topic_1), m_topic_2 = mean(topic_2), m_topic_3 = mean(topic_3), m_topic_4 = mean(topic_4), m_topic_5 = mean(topic_5), m_topic_6 = mean(topic_6), m_topic_7 = mean(topic_7), m_topic_8 = mean(topic_8), m_topic_9 = mean(topic_9), m_topic_10 = mean(topic_10), m_topic_11 = mean(topic_11), m_topic_12 = mean(topic_12), m_topic_13 = mean(topic_13), m_topic_14 = mean(topic_14), m_topic_15 = mean(topic_15), m_topic_16 = mean(topic_16), m_topic_17 = mean(topic_17), m_topic_18 = mean(topic_18), m_topic_19 = mean(topic_19), m_topic_20 = mean(topic_20), n_wine = n()) %>% filter(n_wine>1000)

cbind(province_topic,max_prob_topic=
colnames(province_topic[c(-1,-22,-23)])[max.col(province_topic[c(-1,-22,-23)],ties.method="first")])
```

We suspected that the vintage of each wine (year it was produced) may influence quality. So we extracted the year variable from the title of the review. However, since we don't know the date of each wine review we are unable to calculate the age of the wine at time of review. To accomidate for this we bucketed wines into 4 vintage groups 2010-2017, 2000-2009, 1980-1999, and 1950-1979. 

```{r}
#Constructing a function to later use to extract year from a string
yearExtract <- function(string) {
  t <- regmatches(string, regexec("[0-9]{4}", string))
  sapply(t, function(x) {
    if(length(x) > 0){
      return(as.numeric(x))
    } else {
      return(NA)    
    }
  })
}
```

```{r}
#Use our new function to extract the vintage year from wine `title`. Note, around 5% of wines don't have a year in the title and the regex match can possibly catch a 4 digit number other than year if present.
articles_w_topics20$vintage_year = (yearExtract(as.character(articles_w_topics20$title)))
articles_w_topics20 <- articles_w_topics20[!is.na(articles_w_topics20$vintage_year),]
```

```{r}
#Create a new variable that is a categorical grouping of the year.
articles_w_topics20$vintage_year_cat = NA
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=2010&articles_w_topics20$vintage_year<=2017] <- "2010-2017"
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=2000&articles_w_topics20$vintage_year<=2009] <- "2000-2009"
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=1980&articles_w_topics20$vintage_year<=1999] <- "1980-1999"
articles_w_topics20$vintage_year_cat[articles_w_topics20$vintage_year>=1950&articles_w_topics20$vintage_year<=1979] <- "1950-1979"
```

##Regression
Now we are ready to to perform regression analysis, however, we will first create a 80:20 training/testing split to validate our model. 
```{r}
#Now let's create a train test split
set.seed(42) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 80% of data as sample from total 'n' rows of the data  
sample <- sample.int(n = nrow(articles_w_topics20), size = floor(.80*nrow(articles_w_topics20)), replace = F)
train <- articles_w_topics20[sample, ]
test  <- articles_w_topics20[-sample, ]
```

We attempted to use principal component analysis to attempt to reduce the number of topics in order to increase interpretability of our model. However, since the topic models are generated in a way that each topic is maximally independent of each other, this approach is not effective as each principal component explains a small amount of variance in the data.

```{r}
#PCA - not effective because topics are calculated to assume minimum correlation
topics <- prcomp(articles_w_topics20[,c(14:33)], scale=TRUE)
round(topics$rotation, 5)

cpve <- 100*cumsum((topics$sdev)^2)/20   

# Scree plot of CPVE's
plot(seq(1:20), cpve, pch=16, ylim=c(0, 100),
     main="Cumulative Proportion of Variance Explained",
     xlab="Number of PC's Used")
```


```{r}
#Generate a model:

# summary(lm(points ~ log(price)+ taster_name + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20 + topic_21 + topic_22 + topic_23 + topic_24 + topic_25 + topic_26 + topic_27 + topic_28 + topic_29 + topic_30, articles_w_topics30))

summary(lm(points ~ log(price) + taster_name + vintage_year_cat + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20, train))

# Run regsubsets for model selection
subsets = regsubsets(points ~ log(price) + taster_name + country_trimmed + vintage_year_cat + topic_1 + topic_2 + topic_3 + topic_4 + topic_5 + topic_6 + topic_7 + topic_8 + topic_9 + topic_10 + topic_11 + topic_12 + topic_13 + topic_14 + topic_15 + topic_16 + topic_17 + topic_18 + topic_19 + topic_20, data=train, nvmax=50,method="backward")

#sumarize and print results
subsets.fit = summary(subsets)
subsets.fit$which
data.frame(variables = (1:length(subsets.fit$rsq)),
           r_squared = subsets.fit$rsq,
           rss = subsets.fit$rss,
           bic = subsets.fit$bic,
           cp = subsets.fit$cp)
coef(subsets,20)

plot(subsets.fit$rsq, xlab="Number of predictors", ylab="R-square", col="red", type="p", pch=16)
plot(subsets.fit$rss, xlab="Number of predictors", ylab="RSS", col="blue", type="p", pch=16)

plot(subsets.fit$cp, xlab="Number of predictors", 
     ylab="cp", col="red", type="p", pch=16)
plot(subsets.fit$bic, xlab="Number of predictors", 
     ylab="bic", col="blue", type="p", pch=16)
plot(subsets.fit$adjr2, xlab="Number of predictors", 
     ylab="adjr2", col="green", type="p", pch=16)
```


```{r}
#Random Forest
rf.fit <- randomForest(points ~ log_price + taster_name  + country_trimmed + topic_1 + topic_2 + topic_3 + topic_5 + topic_7 +  topic_8 + topic_10 + topic_11 + topic_14 + topic_15 + topic_17, data=train, mtry=5, ntree=100)
summary(rf.topics)
```


```{r}
#final model
final.lm <- lm(points ~ log(price) + taster_name + country_trimmed + topic_1 + topic_2 + topic_3 + topic_5 + topic_7 +  topic_8 + topic_10 + topic_11 + topic_14 + topic_15 + topic_17, data=train)

summary(final.lm)

test_MSE <- mean(((test$points - predict.lm(final.lm, test))^2),na.rm = TRUE)
test_MSE
```
